data:
  dataset_config: dummy_experiment/dummy_dataset_config.yaml

model:
  epochs: 50
  batch_size: 2
  optimizer: adam # sgd_mom, adam
  learning_rate: 0.01
  lr_decay_after_epoch: 0
  lr_decay_param: 0.1
  backbone: linknet # unet, linknet
  encoder:
    backbone: densenet121 # densenet121, resnet34
    weights: imagenet # imagenet or None
  decoder:
    activation: softmax # softmax or None

logging:
  interval: 10
  mlruns_folder: ./mlruns